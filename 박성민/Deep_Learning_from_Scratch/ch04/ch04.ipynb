{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신경망 학습"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터에서 학습"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 주도 학습\n",
    "기계학습의 중심에는 `데이터` 존재"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련, 시험 데이터\n",
    "나누는 이유: 원하는 것이 범용적으로 사용할 수 있는 모델이기 때문이다. 즉, `범용 능력`을 제대로 평가하기 위해 두 개의 데이터로 나눈다.\n",
    "\n",
    "`오버피팅`: 한 데이터셋에만 지나치게 최적화된 상태"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실 함수\n",
    "신경망에서 '하나의 지표'를 기준으로 최적의 매개변수 값을 탐색함. 이 때 사용되는 지표가 `손실 함수(loss function)`이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오차제곱합\n",
    "$$E = \\frac{1}{2}\\sum_{k}(y_k - t_k)^2$$\n",
    "변수 | 설명\n",
    ":---:|----\n",
    "k    | 데이터 차원 수\n",
    "$y_k$|신경망의 출력\n",
    "$t_k$|정답 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차제곱합\n",
    "def sum_squares_error(y, t):\n",
    "    return 0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 엔트로피 오차\n",
    "$$E=-\\sum_{k}t_k\\log y_k$$\n",
    "여기서 $\\log$는 자연로그 ($\\log_e$)다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차 엔트로피 오차\n",
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delta는 np.log에 0이 들어가 -inf값이 되지 않게 한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미니 배치 학습\n",
    "모든 훈련 데이터에 대한 손실 함수의 합\n",
    "* 교차 엔트로피 오차\n",
    "$$E=-\\frac{1}{N} \\sum_{n} \\sum_{k} t_{nk}\\log y_{nk}$$\n",
    "\n",
    "모든 데이터를 대상으로 손실 함수의 합을 구하려면 시간이 오래 걸린다. 이 경우 데이터 일부를 추려 전체의 '근사치'로 이용하는 방법을 이용할 수 있다. 신경망 학습에서는 일부만 골라 학습을 수행하는 것을 `미니배치 학습`이라고 한다. 데이터의 일부를 `미니배치`라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Creating pickle file ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터에서 무작위로 10장만 빼내기\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (배치용) 교차 엔트로피 오차 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 레이블이 one-hot encoding인 경우\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t * np.log(y + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 레이블이 one-hot encoding이 아닌 경우\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t * np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실 함수 설정 이유\n",
    "정확도를 지표로 삼으면 안되는 이유: 정확도에는 연속적인 변화가 없기 때문에 미분이 대부분의 장소에서 0이 되기 때문\n",
    "손실 함수를 지표로 삼는 이유: 매개변수의 값이 조금만 변해도 이에 반응하여 연속적으로 손실 함수의 값이 변하며, 미분 값도 연속적으로 변하기 때문"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수치 미분\n",
    "기울기의 정의와 성질"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미분\n",
    "$$\\frac{df(x)}{dx} = \\lim_{h \\to 0}\\frac{f(x+h) - f(x)}{h}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나쁜 구현\n",
    "def numerical_diff(f, x):\n",
    "    h = 1e-50       # 반올림 오차(rounding error) 문제 \n",
    "    return (f(x + h) - f(x)) / h\n",
    "\n",
    "# 오차를 줄이기 위해 중심(중앙) 차분을 사용\n",
    "def numerical_diff(f, x):\n",
    "    h = 1e-4\n",
    "    return (f(x + h) - f(x - h)) / (2*h)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수치 미분 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(x):\n",
    "    return 0.01*x**2 + 0.1*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0.0, 20.0, 0.1)\n",
    "y = function_1(x)\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1999999999990898\n",
      "0.2999999999986347\n"
     ]
    }
   ],
   "source": [
    "# x = 5 일 때, x = 10 일 때 기울기\n",
    "print(numerical_diff(function_1, 5))\n",
    "print(numerical_diff(function_1, 10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 편미분\n",
    "$$f(x_0, x_1) = x_0^2 + x_1^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2 # np.sum(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.00000000000378"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x0 = 3, x1 = 4 일 때, x0에 대한 편미분\n",
    "def function_tmp1(x0):\n",
    "    return x0*x0 + 4.0**2.0\n",
    "\n",
    "numerical_diff(function_tmp1, 3.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.999999999999119"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x0 = 3, x1 = 4 일 때, x1에 대한 편미분\n",
    "def function_tmp2(x1):\n",
    "    return 3.0**2.0 + x1*x1\n",
    "\n",
    "numerical_diff(function_tmp2, 4.0) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기울기\n",
    "**기울기**: 모든 변수의 편미분을 벡터로 정리한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "\n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "\n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x)\n",
    "\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 8.] [0. 4.] [6. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(numerical_gradient(function_2, np.array([3., 4.])), \\\n",
    "        numerical_gradient(function_2, np.array([0., 2.])), \\\n",
    "        numerical_gradient(function_2, np.array([3., 0.])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기울기가 가리키는 쪽은 각 장소에서 함수의 출력 값을 가장 크게 줄이는 방향이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경사법(경사 하강법)\n",
    "경사법: 현 위치에서 기울어진 방향으로 일정 거리만큼 이동 후 이동한 곳에서 또다시 기울기를 구하고 기울어진 방향으로 나아가기를 반복하는 과정으로 함수의 값을 점차 줄이는 것\n",
    "$$\n",
    "x_0 = x_0 - \\eta \\frac{\\partial f}{\\partial x_0} \\\\\n",
    "x_1 = x_1 - \\eta \\frac{\\partial f}{\\partial x_1}\n",
    "$$\n",
    "$\\eta$(학습률): 매개변수 값을 얼마나 갱신하느냐를 정하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "\n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr*grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.11110793e-10,  8.14814391e-10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_x = np.array([-3., 4.])\n",
    "gradient_descent(function_2, init_x=init_x, lr=0.1, step_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.58983747e+13 -1.29524862e+12]\n",
      "[-2.99999994  3.99999992]\n"
     ]
    }
   ],
   "source": [
    "# 학습률이 너무 크거나 작으면 좋은 결과를 얻을 수 없음\n",
    "init_x = np.array([-3., 4.])\n",
    "print(gradient_descent(function_2, init_x=init_x, lr=10.0, step_num=100))\n",
    "init_x = np.array([-3., 4.])\n",
    "print(gradient_descent(function_2, init_x=init_x, lr=1e-10, step_num=100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망에서의 기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2, 3) # 정규분포로 초기화\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.76974458 -0.55827334  2.32056154]\n",
      " [-0.09964616  0.11512958 -0.07206914]]\n"
     ]
    }
   ],
   "source": [
    "net = simpleNet()\n",
    "print(net.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.15152829 -0.23134738  1.3274747 ]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.6, 0.9])\n",
    "p = net.predict(x)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7369023000169"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([1, 0, 0])\n",
    "net.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.56113679  0.0975344   0.46360238]\n",
      " [-0.84170518  0.14630161  0.69540358]]\n"
     ]
    }
   ],
   "source": [
    "def f(W):\n",
    "    return net.loss(x, t)\n",
    "\n",
    "f = lambda w: net.loss(x, t)\n",
    "\n",
    "dW = numerical_gradient(f, net.W)\n",
    "print(dW)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 알고리즘 구현\n",
    "1. 미니배치\n",
    "2. 기울기 산출\n",
    "3. 매개변수 갱신\n",
    "4. 반복\n",
    "\n",
    "`확률적 경사 하강법(SGD)` stochastic gradient descent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2층 신경망 클래스 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "\n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "\n",
    "        return cross_entropy_error(y, t)\n",
    "\n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "\n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(100, 784)\n",
    "t = np.random.rand(100, 10)\n",
    "\n",
    "grads = net.numerical_gradient(x, t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미니배치 학습 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import gradient\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_loss_list = []\n",
    "\n",
    "# 하이퍼파라미터\n",
    "iters_num = 1000 # 반복횟수\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100 # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    # 기울기 계산\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradi\n",
    "\n",
    "    # 매개 변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "\n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 횟수가 늘어가면서 손실 함수의 값이 줄어든다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시험 데이터 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "# 하이퍼파라미터\n",
    "iters_num = 1000 # 반복횟수\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100 # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1 epoch당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    # 기울기 계산\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "\n",
    "    # 매개 변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "\n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "\n",
    "    # 1 epoch당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(f'train acc, test acc | {str(train_acc)}, {str(test_acc)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a13f5bb60a88f91a902d04e4c145b424e72f3cecdd63854619232637e50b1f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
