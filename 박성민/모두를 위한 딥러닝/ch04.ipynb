{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab04-1 Multivariate Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Linear Regression\n",
    "입력이 여러개일 때 쓴다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Function\n",
    "$$\n",
    "H(x) = \\mathbf{W} x + b\n",
    "$$\n",
    "$x$는 벡터 형태의 입력이고, $\\mathbf{W}$는 matrix 형태이다.\n",
    "\n",
    "$$\n",
    "H(x) = w_1x_1 + w_2x_2 + w_3x_3 + b\n",
    "$$\n",
    "입력 변수가 3개라면 weight도 3개이다.\n",
    "\n",
    "```py\n",
    "# 단순 H(x)계산\n",
    "hypothesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b\n",
    "\n",
    "# matmul()함수 사용\n",
    "hypothesis = x_train.matmul(W) + b\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function: MSE\n",
    "\n",
    "```py\n",
    "cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent with torch.optim\n",
    "```py\n",
    "# optimizer 설정\n",
    "optimizer = torch.optim.SGD([W, b], lr=1e-5)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "cost.backward()\n",
    "optimizer.step()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Code with torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 hypothesis: tensor([0., 0., 0., 0., 0.]), Cost: 29661.800781\n",
      "Epoch    1/20 hypothesis: tensor([67.2578, 80.8397, 79.6523, 86.7394, 61.6605]), Cost: 9298.520508\n",
      "Epoch    2/20 hypothesis: tensor([104.9128, 126.0990, 124.2466, 135.3015,  96.1821]), Cost: 2915.712402\n",
      "Epoch    3/20 hypothesis: tensor([125.9942, 151.4381, 149.2133, 162.4896, 115.5097]), Cost: 915.040527\n",
      "Epoch    4/20 hypothesis: tensor([137.7968, 165.6247, 163.1911, 177.7112, 126.3307]), Cost: 287.936005\n",
      "Epoch    5/20 hypothesis: tensor([144.4044, 173.5674, 171.0168, 186.2332, 132.3891]), Cost: 91.371010\n",
      "Epoch    6/20 hypothesis: tensor([148.1035, 178.0144, 175.3980, 191.0042, 135.7812]), Cost: 29.758139\n",
      "Epoch    7/20 hypothesis: tensor([150.1744, 180.5042, 177.8508, 193.6753, 137.6805]), Cost: 10.445305\n",
      "Epoch    8/20 hypothesis: tensor([151.3336, 181.8983, 179.2240, 195.1707, 138.7440]), Cost: 4.391228\n",
      "Epoch    9/20 hypothesis: tensor([151.9824, 182.6789, 179.9928, 196.0079, 139.3396]), Cost: 2.493135\n",
      "Epoch   10/20 hypothesis: tensor([152.3454, 183.1161, 180.4231, 196.4765, 139.6732]), Cost: 1.897688\n",
      "Epoch   11/20 hypothesis: tensor([152.5485, 183.3610, 180.6640, 196.7389, 139.8602]), Cost: 1.710541\n",
      "Epoch   12/20 hypothesis: tensor([152.6620, 183.4982, 180.7988, 196.8857, 139.9651]), Cost: 1.651412\n",
      "Epoch   13/20 hypothesis: tensor([152.7253, 183.5752, 180.8742, 196.9678, 140.0240]), Cost: 1.632387\n",
      "Epoch   14/20 hypothesis: tensor([152.7606, 183.6184, 180.9164, 197.0138, 140.0571]), Cost: 1.625923\n",
      "Epoch   15/20 hypothesis: tensor([152.7802, 183.6427, 180.9399, 197.0395, 140.0759]), Cost: 1.623412\n",
      "Epoch   16/20 hypothesis: tensor([152.7909, 183.6565, 180.9530, 197.0538, 140.0865]), Cost: 1.622141\n",
      "Epoch   17/20 hypothesis: tensor([152.7968, 183.6643, 180.9603, 197.0618, 140.0927]), Cost: 1.621253\n",
      "Epoch   18/20 hypothesis: tensor([152.7999, 183.6688, 180.9644, 197.0662, 140.0963]), Cost: 1.620500\n",
      "Epoch   19/20 hypothesis: tensor([152.8014, 183.6715, 180.9666, 197.0686, 140.0985]), Cost: 1.619770\n",
      "Epoch   20/20 hypothesis: tensor([152.8020, 183.6731, 180.9677, 197.0699, 140.1000]), Cost: 1.619033\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "# 모델 초기화\n",
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# optimizer 설정\n",
    "optimizer = torch.optim.SGD([W, b], lr=1e-5)\n",
    "\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs+1):\n",
    "    # H(x) 계산\n",
    "    hypothesis = x_train.matmul(W) + b\n",
    "\n",
    "    # cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    \n",
    "    # cost 로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch:4d}/{nb_epochs} hypothesis: {hypothesis.squeeze().detach()}, Cost: {cost.item():.6f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Module\n",
    "```py\n",
    "# 모델 초기화\n",
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# H(x) 계산\n",
    "hypothesis = x_train.matmul(W) + b\n",
    "\n",
    "# 대신\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "hypothesis = model(x_train)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F.mse_loss\n",
    "```py\n",
    "# cost 계산\n",
    "cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "\n",
    "# 대신 \n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# cost 계산\n",
    "cost = F.mse_loss(prediction, y_train)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 hypothesis: tensor([-32.4065, -37.8621, -37.7747, -42.1342, -27.8076]), Cost: 43328.320312\n",
      "Epoch    1/20 hypothesis: tensor([48.8843, 59.8438, 58.4964, 62.7026, 46.7175]), Cost: 13581.401367\n",
      "Epoch    2/20 hypothesis: tensor([ 94.3960, 114.5457, 112.3950, 121.3969,  88.4414]), Cost: 4257.321289\n",
      "Epoch    3/20 hypothesis: tensor([119.8762, 145.1714, 142.5708, 154.2576, 111.8011]), Cost: 1334.718628\n",
      "Epoch    4/20 hypothesis: tensor([134.1416, 162.3177, 159.4652, 172.6551, 124.8795]), Cost: 418.636963\n",
      "Epoch    5/20 hypothesis: tensor([142.1282, 171.9173, 168.9236, 182.9552, 132.2016]), Cost: 131.494110\n",
      "Epoch    6/20 hypothesis: tensor([146.5995, 177.2918, 174.2191, 188.7218, 136.3011]), Cost: 41.490135\n",
      "Epoch    7/20 hypothesis: tensor([149.1027, 180.3009, 177.1838, 191.9503, 138.5963]), Cost: 13.278364\n",
      "Epoch    8/20 hypothesis: tensor([150.5041, 181.9856, 178.8436, 193.7578, 139.8814]), Cost: 4.435555\n",
      "Epoch    9/20 hypothesis: tensor([151.2886, 182.9288, 179.7728, 194.7698, 140.6009]), Cost: 1.663644\n",
      "Epoch   10/20 hypothesis: tensor([151.7278, 183.4570, 180.2930, 195.3363, 141.0038]), Cost: 0.794747\n",
      "Epoch   11/20 hypothesis: tensor([151.9735, 183.7527, 180.5843, 195.6535, 141.2295]), Cost: 0.522290\n",
      "Epoch   12/20 hypothesis: tensor([152.1111, 183.9184, 180.7473, 195.8310, 141.3559]), Cost: 0.436808\n",
      "Epoch   13/20 hypothesis: tensor([152.1880, 184.0112, 180.8385, 195.9304, 141.4267]), Cost: 0.409943\n",
      "Epoch   14/20 hypothesis: tensor([152.2310, 184.0632, 180.8896, 195.9860, 141.4665]), Cost: 0.401443\n",
      "Epoch   15/20 hypothesis: tensor([152.2549, 184.0923, 180.9181, 196.0172, 141.4888]), Cost: 0.398681\n",
      "Epoch   16/20 hypothesis: tensor([152.2683, 184.1087, 180.9341, 196.0345, 141.5013]), Cost: 0.397744\n",
      "Epoch   17/20 hypothesis: tensor([152.2757, 184.1180, 180.9430, 196.0443, 141.5085]), Cost: 0.397370\n",
      "Epoch   18/20 hypothesis: tensor([152.2797, 184.1232, 180.9480, 196.0497, 141.5125]), Cost: 0.397171\n",
      "Epoch   19/20 hypothesis: tensor([152.2819, 184.1262, 180.9507, 196.0527, 141.5148]), Cost: 0.397027\n",
      "Epoch   20/20 hypothesis: tensor([152.2831, 184.1279, 180.9523, 196.0544, 141.5162]), Cost: 0.396905\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "# 모델 초기화\n",
    "model = MultivariateLinearRegressionModel()\n",
    "W = model.linear.weight\n",
    "b = model.linear.bias\n",
    "\n",
    "# optimizer 설정\n",
    "optimizer = torch.optim.SGD([W, b], lr=1e-5)\n",
    "\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs+1):\n",
    "    # H(x) 계산\n",
    "    hypothesis = model(x_train)\n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(hypothesis, y_train)\n",
    "    \n",
    "    # cost 로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch:4d}/{nb_epochs} hypothesis: {hypothesis.squeeze().detach()}, Cost: {cost.item():.6f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab04-2 Loading Data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Minibatch\" Gradient Descent\n",
    "데이터 일부로 학습한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.x_data = [[73, 80, 75],\n",
    "                       [93, 88, 93],\n",
    "                       [89, 91, 90],\n",
    "                       [96, 98, 100],\n",
    "                       [73, 66, 70]]\n",
    "        self.y_data = [[152], [185], [180], [196], [142]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "        return x, y\n",
    "\n",
    "dataset = CustomDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataLoader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2, # 미니배치 크기, 일반적으로 2의 제곱수로 설정한다.(2, 4, 8, ...)\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full code with Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Batch 1/3 Cost: 0.155487\n",
      "Epoch    0/20 Batch 2/3 Cost: 1.003635\n",
      "Epoch    0/20 Batch 3/3 Cost: 0.000126\n",
      "Epoch    1/20 Batch 1/3 Cost: 0.306942\n",
      "Epoch    1/20 Batch 2/3 Cost: 0.606459\n",
      "Epoch    1/20 Batch 3/3 Cost: 0.202264\n",
      "Epoch    2/20 Batch 1/3 Cost: 0.438182\n",
      "Epoch    2/20 Batch 2/3 Cost: 0.157852\n",
      "Epoch    2/20 Batch 3/3 Cost: 0.688954\n",
      "Epoch    3/20 Batch 1/3 Cost: 0.166257\n",
      "Epoch    3/20 Batch 2/3 Cost: 0.793525\n",
      "Epoch    3/20 Batch 3/3 Cost: 0.008346\n",
      "Epoch    4/20 Batch 1/3 Cost: 0.275853\n",
      "Epoch    4/20 Batch 2/3 Cost: 0.629544\n",
      "Epoch    4/20 Batch 3/3 Cost: 0.193495\n",
      "Epoch    5/20 Batch 1/3 Cost: 0.050203\n",
      "Epoch    5/20 Batch 2/3 Cost: 0.246860\n",
      "Epoch    5/20 Batch 3/3 Cost: 1.225606\n",
      "Epoch    6/20 Batch 1/3 Cost: 0.654072\n",
      "Epoch    6/20 Batch 2/3 Cost: 0.059007\n",
      "Epoch    6/20 Batch 3/3 Cost: 0.919358\n",
      "Epoch    7/20 Batch 1/3 Cost: 0.895725\n",
      "Epoch    7/20 Batch 2/3 Cost: 0.414997\n",
      "Epoch    7/20 Batch 3/3 Cost: 0.057230\n",
      "Epoch    8/20 Batch 1/3 Cost: 0.094718\n",
      "Epoch    8/20 Batch 2/3 Cost: 0.689483\n",
      "Epoch    8/20 Batch 3/3 Cost: 0.006870\n",
      "Epoch    9/20 Batch 1/3 Cost: 0.685769\n",
      "Epoch    9/20 Batch 2/3 Cost: 0.002893\n",
      "Epoch    9/20 Batch 3/3 Cost: 0.148773\n",
      "Epoch   10/20 Batch 1/3 Cost: 0.495741\n",
      "Epoch   10/20 Batch 2/3 Cost: 0.472402\n",
      "Epoch   10/20 Batch 3/3 Cost: 0.070055\n",
      "Epoch   11/20 Batch 1/3 Cost: 0.054715\n",
      "Epoch   11/20 Batch 2/3 Cost: 0.740983\n",
      "Epoch   11/20 Batch 3/3 Cost: 0.006366\n",
      "Epoch   12/20 Batch 1/3 Cost: 0.329242\n",
      "Epoch   12/20 Batch 2/3 Cost: 0.712004\n",
      "Epoch   12/20 Batch 3/3 Cost: 0.000544\n",
      "Epoch   13/20 Batch 1/3 Cost: 0.686801\n",
      "Epoch   13/20 Batch 2/3 Cost: 0.003556\n",
      "Epoch   13/20 Batch 3/3 Cost: 0.154765\n",
      "Epoch   14/20 Batch 1/3 Cost: 0.509286\n",
      "Epoch   14/20 Batch 2/3 Cost: 0.005223\n",
      "Epoch   14/20 Batch 3/3 Cost: 0.712713\n",
      "Epoch   15/20 Batch 1/3 Cost: 0.840824\n",
      "Epoch   15/20 Batch 2/3 Cost: 0.038720\n",
      "Epoch   15/20 Batch 3/3 Cost: 0.089517\n",
      "Epoch   16/20 Batch 1/3 Cost: 0.051714\n",
      "Epoch   16/20 Batch 2/3 Cost: 0.199242\n",
      "Epoch   16/20 Batch 3/3 Cost: 1.314356\n",
      "Epoch   17/20 Batch 1/3 Cost: 0.733042\n",
      "Epoch   17/20 Batch 2/3 Cost: 0.016834\n",
      "Epoch   17/20 Batch 3/3 Cost: 0.816429\n",
      "Epoch   18/20 Batch 1/3 Cost: 0.819855\n",
      "Epoch   18/20 Batch 2/3 Cost: 0.144462\n",
      "Epoch   18/20 Batch 3/3 Cost: 0.015069\n",
      "Epoch   19/20 Batch 1/3 Cost: 0.419078\n",
      "Epoch   19/20 Batch 2/3 Cost: 0.455061\n",
      "Epoch   19/20 Batch 3/3 Cost: 0.005647\n",
      "Epoch   20/20 Batch 1/3 Cost: 0.419294\n",
      "Epoch   20/20 Batch 2/3 Cost: 0.621940\n",
      "Epoch   20/20 Batch 3/3 Cost: 0.018588\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs+1):\n",
    "    for batch_idx, samples in enumerate(dataLoader):\n",
    "        x_train, y_train = samples\n",
    "        # H(x) 계산\n",
    "        prediction = model(x_train)\n",
    "\n",
    "        # cost 계산\n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "        \n",
    "        # cost 로 H(x) 개선\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch {epoch:4d}/{nb_epochs} Batch {batch_idx+1}/{len(dataLoader)} Cost: {cost.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a13f5bb60a88f91a902d04e4c145b424e72f3cecdd63854619232637e50b1f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
